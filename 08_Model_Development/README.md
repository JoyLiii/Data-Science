## 機器學習演算法

機器學習的演算法可以大致分為監督式學習與非監督式學習，兩者的差別在於是否知道標準答案

- 監督式學習好比說學生寫作業對答案，我們從錯誤中學習，有老師跟我們說標準答案，告訴我們這個世界的基準是什麼
  - 分類
  - 預測
- 非監督式學習會讓小孩去自己學習，例如你帶他去一趟動物園之後，他可能會歸納說猴子跟猩猩很像，老虎跟貓很像，藉此從資料中學習一套法則，但你並沒有跟他說答案
  - 分群
  - 降維
<img width="524" alt="螢幕快照 2021-08-29 上午11 07 01" src="https://user-images.githubusercontent.com/40282726/131237087-733c4146-2d5d-435d-93fa-e77412d427f2.png">

## 過度擬合
若實作機器學習之後會常常聽見的名詞，過度擬合(overfitting)

機器會根據資料來進行學習，但倘若它過度擬合這些圓點，而使用一個過度複雜的模型(右圖)，雖然在訓練的時候得到比較好的成效，但通常在沒看過的資料成效會大打折扣

![image](https://user-images.githubusercontent.com/40282726/131237697-dc98f81d-ada3-4d4c-b953-a33a1fc33c46.png)

為了防止這種情況，我們可以...
- 收集更多資料(但也意味者成本提高)
- 用資料增補(Data Augmentation)
  這招常常使用在影像辨識，由於收集的資料有限，我們可以將既有的資料進行旋轉、光暗調整、縮小放大等等進行調整，就可以倍增很多資料
- 重新進行資料探索，合併或減少沒有用的特徵
- 正規化，有 L1、L2 regularization。在演算法的 loss 計算加上懲罰項，如此一來機器在進行訓練時來約束模型不要過度擬合

## 交叉驗證
前面有提過在資料進行預測之前，通常會將資料進行分割。

但是我們很可能會遇到極端的狀況是，我們剛好切出來的驗證集資料跟訓練集很有相關，為了避免這種狀況發生，我們可以進行交叉驗證。

所謂的交叉驗證是將訓練資料進行多次不同的切割，輪流當驗證集，最後計算的時候取平均，比較能了解資料在不同情況下的成效。

![image](https://user-images.githubusercontent.com/40282726/131237686-e4552637-a4dd-4567-bafc-8a26b6211f08.png)
